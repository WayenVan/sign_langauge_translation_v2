defaults:
  - base_gfslt-vlp
  # - override modules: dinov2_base
  # - override model: mbart_slt
  - override model: gemma_slt_pe_shuffle
  # - override data: ph14t_*x224x224_gfslt
  # - override data: ph14t_*x224x224_gemmaslt_multiling
  - override data: ph14t_*x224x224_gemmaslt
  # - override engine: adam_cosine_anneal

data:
  train:
    loader_kwargs:
      batch_size: 1
      num_workers: 6
  val:
    loader_kwargs:
      batch_size: 1
      num_workers: 6

max_epochs: 200
devices: [0, 1]
# precision: 16-mixed
precision: bf16-mixed

model:
  llm_dtype: bfloat16
  # llm_dtype: float16

engine:
  optimizer:
    lr: 1e-4
  lr_scheduler:
    instance:
      eta_min: 1e-8

visual_text_alignment_weight: 1.0
log_interval: 10
pretraining: true
